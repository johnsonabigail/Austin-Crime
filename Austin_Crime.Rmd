---
title: "Austin_Crime"
author: "Kevin, Elle, Abigail"
date: "5/4/2022"
output: md_document
always_allow_html: true
---

```{r Loading Libraries, echo=TRUE, message=FALSE, warning=FALSE, show=FALSE}
library(tidyverse)
library(mosaic)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggmap)
library(geojsonio)
library(broom)
library(data.table)
library(rsample)
library(caret)
library(modelr)
library(knitr)
library(parallel)
library(foreach)
library(pdp)
library(rpart)
library(rpart.plot)
library(gbm)
library(randomForest)
library(glmnet)
library(kableExtra)
library(pROC)
```

# Data Visualization
## Feature Engineering and Data Loading
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
obs <- read_csv("austin_crime.csv")

# Encode the crime target variable of interest
# 1 if "Cleared by Arrest", 0 otherwise
obs$clearance_status <- ifelse(obs$clearance_status == "Cleared by Arrest", 1, 0)

# Omit any missing rows for clearance status
obs <- filter(obs, clearance_status != "NA")
# This result in ~40k observations being dropped

# We determine the arrest rate, and append it to our zip-code level data
t1 <- obs %>% mutate(number_crimes = n_distinct(unique_key)) %>%
    group_by(zipcode) %>% 
    summarise(arrest_rate =(sum(clearance_status))/sum(number_crimes))

zip_list <- as.data.frame(t1$zipcode)
zip_list <- as.character(zip_list$`t1$zipcode`)

zip <- read_csv("austin_crime_zips.csv")
zip <- select(zip, 
              c(zipcode, population_density, median_income, median_home_value,
                prop_white,arrest_rate))
zip$arrest_rate <- scale(zip$arrest_rate)
zip$zipcode <- as.character(zip$zipcode)


tx <- geojson_read("tx_zip_geo.json", what = "sp")


## Final cleaning steps: Encoding zip as a factor with 45 levels, and dropping NA values
## Resulting in 27459 observations remaining
table <- merge(obs, zip, by = "zipcode") %>% drop_na()
table$zipcode = as.factor(table$zipcode)

## We want to set some data aside for validation at the end.. so we conduct a split..


```

# Data Visualization
## Subsetting geojson
```{r Data Cleaning2, message=FALSE, warning=FALSE, echo=FALSE}
# Subsetting our geojson such that only the zipcodes of interest are included...

# Transforming to a frame for ggplot...
tx_fortified <- tidy(tx, region = "ZCTA5CE10")
tx_sub <- setDT(tx_fortified)[id %chin% zip_list]

tx_sub <- tx_sub %>% left_join(.,zip, by= c("id"="zipcode"))
tx_sub <- na.omit(tx_sub)

```

# Data Visualization
## Visualizing
```{r Data Cleaning3, message=FALSE, warning=FALSE, echo=FALSE}
options(scipen = 10000)

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_income, x = long, y = lat, group = group,), color = 'black') + ggtitle("Median Income in Austin Area Zipcodes (USD)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_home_value, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Median Home Value in Austin Area Zipcodes (USD)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = prop_white, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Proportion of Population that is White in Austin Zipcodes")

ggplot() + geom_polygon(data = tx_sub, aes(fill = arrest_rate, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Normalized Proportion of Police Reports Leading to Arrest in Austin Zipcodes")
```

# Question: Does Race play a part in the prevailing arrest rate?
## Some Visualizations...
```{r Ethnicity Effects, message=FALSE, warning=FALSE, echo=FALSE}


ggplot(data = zip) + geom_point(aes(x=prop_white, y=arrest_rate, color = population_density)) +theme_linedraw()+ ggtitle("Proportion of Residents Who are White vs. Normalized Arrest Rate")
ggplot(data=zip) + geom_point(aes(x=prop_white, y=median_home_value))+theme_linedraw()+ ggtitle("Proportion of Residents Who are White vs. Median Home Value")
ggplot(data=zip) + geom_point(aes(x=population_density, y=arrest_rate))+theme_linedraw()+ ggtitle("Normalized Arrest Rate vs ZipCode Population Density(People/Sq Mile)")


```

```{r data_description, message=FALSE, warning=FALSE, echo=FALSE}
table <- merge(obs, zip, by = "zipcode") %>% drop_na()

Variable <- c("clearance_status", "zipcode", "population_density", "median_income", "median_home_value", "prop_white", "arrest_rate")

Description <- c("whether or not crime is cleared by arrest", " postal zipcode in Austin, TX", "people per square mile", "median income of postal zipcode", "median home value of postal zipcode","proportion of postal zipcode that is white","proportion of crimes cleared by arrest relative to total crimes")

Type <- c("numeric" , "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")

vars_of_interest <- data.frame(Variable, Description, Type)

kable(vars_of_interest, caption = "Data Dictionary")

```


# Models
## First Model: Logistic Regression
We started modeling by recoding dependent variable `clearance_status` to take on the unit value if crime is cleared by arrest and zero otherwise. Also, we dropped all nulls before creating a train/test split with 80 percent of the data going to the training set, while the remaining 20 percent ending up in the testing set data. In our analysis, we chose to include population density, median income, median home price, white population share, and arrest rate as independent variables. The resulting model is 
\
&nbsp;
  $$
  P(clearance \: status = 1 \mid x_{i,t}) = \beta_0 + \beta_1 population \: density_{i,t} + \beta_2 median \: income_{i,t} + \beta_3 median \: home \: value_{i,t} + \beta_3 prop \: white_{i,t} + \beta_4 arrest \: rate _{i,t}
  $$
\
&nbsp;
The results reveal that `arrest rate`, `median home price`, and `white population share` are highly significant in predicting `clearance_status`, so they should be included in the model. Then, out of sample root mean square error (RMSE) is calculated as a measure of the modelâ€™s out of sample performance. RMSE will be used to compare across all models, and the lower, the better.

Each coefficient shows a ceteris paribus effect of every feature on clearance status. For instance, $\beta_{prop \: white}=-0.67 means that as the share of the white population increases by 1 percent, the probability of crime is cleared by arrest declines by 67 percentage points, holding all other features constant. 

```{r Logistic, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(1)

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)

crime_logit <- glm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate,
                   data = crime_train, family = binomial)



rmse_frame_logit=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)


modelr::rmse(crime_logit,crime_test)
} %>% as.data.frame
# validate_RMSE_logit <- mean(rmse_frame_logit$V1)
## Validated RMSEout of 2.0318

validate_RMSE_logit <- data.frame(mean(rmse_frame_logit$V1))
colnames(validate_RMSE_logit) <- "RMSE"
rownames(validate_RMSE_logit) <- "Logit" 
kable(validate_RMSE_logit)
```

## Second Model: Stepwise Selection
Although the logistic model is simple, it fails to capture context-specific effects by ignoring interaction terms. Stepwise selection computes the best set of variables by including main effects, and pairwise interaction terms that result in the lowest RMSE. The resulting model chosen by stepwise selection is 
\
&nbsp;
    $$
  P(clearance \: status = 1 \mid x_{i,t}) = \beta_0 + \beta_1 population \: density_{i,t} + \beta_2 median \: income_{i,t} + \beta_3 median \: home \: value_{i,t} + \beta_3 prop \: white_{i,t} + \beta_4 arrest \: rate_{i,t} + \beta_5 median\:home\:value \times arrest\:rate
  $$
\
&nbsp;

We notice an interaction term in our model. This term allows the effect of a unit change in $median\:home\:value$ to depend on $arrest\:rate$. The coefficient of this interaction term measures the effect on clearance status of an additional dollar of median home value is greater, by the amount $\beta_5$, for each additional percentage point increase in arrest rate.

By including the interaction term, the model performance is enhanced. RMSE declined from 2.0318 to 2.0254. Other models will be considered in the following sections with the goal of reducing RMSE further.

```{r Stepwise, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(2)
crime_step <- step(crime_logit, scope=~(.)^2)
# stepwise function chose the following model
crime_step <- glm(clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + median_home_value:arrest_rate, data = crime_train, family = binomial)

rmse_frame_step=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)


modelr::rmse(crime_step,crime_test)
} %>% as.data.frame
# validate_RMSE_step = mean(rmse_frame_step$V1)
## Validated RMSEout of 2.0254

validate_RMSE_step <- data.frame(mean(rmse_frame_step$V1))
colnames(validate_RMSE_step) <- "RMSE"
rownames(validate_RMSE_step) <- "Stepwise Selection" 
kable(validate_RMSE_step)
```
    
## Third Model: Random Forest 
The next model performed is random forest. The highlight of tree is that it automatically detect nonlinearities and interactions. So there is no need to include interaction terms. The process involves resampling the data with replacement 500 times and fitting a tree to each one. Then, averaging the predictions of the 500 different trees. However, we can reduce covariance between each tree by using only a subset of the variables. Thus, the 500 trees are diversified and their predictions are less correlated. By introducing more randomness to the process, we can improve both accuracy and prevent over-fitting. The resulting RMSE is 0.3522 which is a significant improvement from the logistic model or stepwise selection.

Figure [figure number here] presents a variable importance plot. It shows that excluding zip code would increase mean square error (MSE) by 26 percent, suggesting that zip code should be included in the model. The process of the calculation involves comparing out-of-bag performance of the model when using the correct zip code versus permuting the zip code for all observations.
```{r Random Forest, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(3)
rmse_frame_forest=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)

crime_forest <- randomForest(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    data = omit_train,
                    importance = TRUE, na.action = na.omit)

modelr::rmse(crime_forest,omit_test)
} %>% as.data.frame
# validate_RMSE_forest = mean(rmse_frame_forest$V1) 
## Validated RMSEout of .3522

validate_RMSE_forest <- data.frame(mean(rmse_frame_forest$V1))
colnames(validate_RMSE_forest) <- "RMSE"
rownames(validate_RMSE_forest) <- "Random Forest" 
kable(validate_RMSE_forest)
```


## Fourth Model: Gradient Boosting
Similarly to the random forest model in the previous section, boosting combines many decision trees where each tree is fitted to the residual of the previous tree. However, the fit in each round will be scaled down to constrain it from explaining the full variation in the data. The resulting estimate is the sum of all crushed trees in each round. The highlight of the gradient boosting technique is that it keeps each tree in the ensemble from overfitting just like when random forest restricts the number of features to prevent overfitting.

Boosting requires choosing three main hyper parameters: (1) Number of trees: 500, (2) Shrinkage Parameter: 0.01, and (3) Interaction Depth: 4

```{r Gradient Boosting, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(4)
rmse_frame_gbm=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)


crime_gbm <- gbm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                 data = crime_train,
                 distribution = "bernoulli",
                 n.trees = 500,
                 shrinkage = 0.01, interaction.depth = 4, cv.folds = 2)

modelr::rmse(crime_gbm,omit_test)
} %>% as.data.frame
# validate_RMSE_gbm = mean(rmse_frame_gbm$V1) 
## RMSEout of 1.984

validate_RMSE_gbm <- data.frame(mean(rmse_frame_gbm$V1))
colnames(validate_RMSE_gbm) <- "RMSE"
rownames(validate_RMSE_gbm) <- "Gradient Boosting" 
kable(validate_RMSE_gbm)
```

## Fifth Model: Lasso Model
```{r Lasso, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(5)
x <- model.matrix(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + as.factor(zipcode),
                  data = table)[,-1] 
#[, -1] excludes first col (intercept)

x <- scale(x, center = TRUE, scale = TRUE) 
y <- table$clearance_status %>% as.factor()
grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x, y, alpha = 1, lambda = grid, family = "binomial")
cv.out <- cv.glmnet(x, y, alpha = 1, family = "binomial", folds=20)
bestlam <- cv.out$lambda.min

plot(lasso.mod)
title("Figure 1: Lasso Coefficients as a Function of L1 Norm", line = 3)

```

```{r Lasso2, warning=FALSE, echo=FALSE}
plot(cv.out)
title("Figure 2: Mean-Squared Error as a Function of log Lambda", line = 3)
```

```{r Lasso3, warning=FALSE, echo=FALSE}
table <- merge(obs, zip, by = "zipcode") %>% drop_na()
table$zipcode = as.factor(table$zipcode)

lasso.coef <- predict(lasso.mod,
                      type = "coefficients",
                      s = bestlam)

LassoCoef <- as.data.table(as.matrix(lasso.coef), keep.rownames = TRUE)
kable(LassoCoef, col.names = c("Predictor", "Estimate"), caption = "**Table 1 Lasso Model Predictor Estimates**", format_caption = c("italic", "underline")) %>%
    kable_styling(bootstrap_options = "striped", full_width = F)


mse = min(cv.out$cvm)
rmse = sqrt(mse)
# .9062
validate_RMSE_lasso <- data.frame(sqrt(mse))
colnames(validate_RMSE_lasso) <- "RMSE"
rownames(validate_RMSE_lasso) <- "Lasso" 
kable(validate_RMSE_lasso)

```


## Confusion Matrix for the best model...
```{r Validation_GBM, message=FALSE, warning=FALSE, echo=FALSE}
pred <- predict(crime_gbm,newdata=crime_test)
confusion_table <- data.frame(fold_id=integer(),
                              TPR=integer(),
                              FPR=integer())

level <- seq(.05,.5,by=.05)

confusion_level <- foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}

gbm_accuracy = (6014+51)/(6014+1023+32+51) # 85.2% accuracy

confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for GBM Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)
accurac7120
gbm_auc = auc(crime_test$clearance_status,pred)
## .669
```
## Confusion Matrix for the second best model...
```{r Validation_RF, message=FALSE, warning=FALSE, echo=FALSE}

pred =predict(crime_forest,newdata=crime_test)
confusion_table = data.frame(fold_id=integer(),TPR=integer(),FPR=integer())

level = seq(.05,.5,by=.05)

confusion_level=foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}


confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for Random Forest Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)


forest_auc = auc(crime_test$clearance_status,pred)
## .667

```

## Sanity-Check: Confusion Matrix for the logit model...
```{r Sanity-Check - Logit Performance, message=FALSE, warning=FALSE, echo=FALSE}

pred = predict(crime_logit, crime_test, type='response')
confusion_table = data.frame(fold_id=integer(),TPR=integer(),FPR=integer())

level = seq(.1,.5,by=.05)

confusion_level=foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}


confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for Random Forest Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)


logit_auc = auc(crime_test$clearance_status,pred)
## .661

```



```{r Variable Importance, message=FALSE, warning=FALSE, echo=FALSE}
## Variable Importance Plots

vi = varImpPlot(crime_forest, type=1)

omit_test = as.data.frame(table)
partialPlot(crime_forest, table, 'prop_white')
partialPlot(crime_forest, table, 'median_home_value')
partialPlot(crime_forest, table, 'median_income')
partialPlot(crime_forest, table, 'population_density')

```