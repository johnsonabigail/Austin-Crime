---
title: "Austin_Crime"
author: "Kevin, Elle, Abigail"
date: "5/4/2022"
output: md_document
always_allow_html: true
---

```{r Loading Libraries, echo=TRUE, message=FALSE, warning=FALSE, show=FALSE}
library(tidyverse)
library(mosaic)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggmap)
library(geojsonio)
library(broom)
library(data.table)
library(rsample)
library(caret)
library(modelr)
library(knitr)
library(parallel)
library(foreach)
library(pdp)
library(rpart)
library(rpart.plot)
library(gbm)
library(randomForest)
library(glmnet)
library(kableExtra)
library(pROC)
```

# Data Visualization
## Feature Engineering and Data Loading
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
obs <- read_csv("austin_crime.csv")

# Encode the crime target variable of interest
# 1 if "Cleared by Arrest", 0 otherwise
obs$clearance_status <- ifelse(obs$clearance_status == "Cleared by Arrest", 1, 0)

# Omit any missing rows for clearance status
obs <- filter(obs, clearance_status != "NA")
# This result in ~40k observations being dropped

# We determine the arrest rate, and append it to our zip-code level data
t1 <- obs %>% mutate(number_crimes = n_distinct(unique_key)) %>%
    group_by(zipcode) %>% 
    summarise(arrest_rate =(sum(clearance_status))/sum(number_crimes))

zip_list <- as.data.frame(t1$zipcode)
zip_list <- as.character(zip_list$`t1$zipcode`)

zip <- read_csv("austin_crime_zips.csv")
zip <- select(zip, 
              c(zipcode, population_density, median_income, median_home_value,
                prop_white,arrest_rate))
zip$arrest_rate <- scale(zip$arrest_rate)
zip$zipcode <- as.character(zip$zipcode)


tx <- geojson_read("tx_zip_geo.json", what = "sp")


## Final cleaning steps: Encoding zip as a factor with 45 levels, and dropping NA values
## Resulting in 27459 observations remaining
table <- merge(obs, zip, by = "zipcode") %>% drop_na()
table$zipcode = as.factor(table$zipcode)

## We want to set some data aside for validation at the end.. so we conduct a split..


```

# Data Visualization
## Subsetting geojson
```{r Data Cleaning2, message=FALSE, warning=FALSE, echo=FALSE}
# Subsetting our geojson such that only the zipcodes of interest are included...

# Transforming to a frame for ggplot...
tx_fortified <- tidy(tx, region = "ZCTA5CE10")
tx_sub <- setDT(tx_fortified)[id %chin% zip_list]

tx_sub <- tx_sub %>% left_join(.,zip, by= c("id"="zipcode"))
tx_sub <- na.omit(tx_sub)

```

# Data Visualization
## Visualizing
```{r Data Cleaning3, message=FALSE, warning=FALSE, echo=FALSE}
options(scipen = 10000)

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_income, x = long, y = lat, group = group,), color = 'black') + ggtitle("Median Income in Austin Area Zipcodes (USD)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_home_value, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Median Home Value in Austin Area Zipcodes (USD)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = prop_white, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Proportion of Population that is White in Austin Zipcodes")

ggplot() + geom_polygon(data = tx_sub, aes(fill = arrest_rate, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Normalized Proportion of Police Reports Leading to Arrest in Austin Zipcodes")
```

# Question: Does Race play a part in the prevailing arrest rate?
## Some Visualizations...
```{r Ethnicity Effects, message=FALSE, warning=FALSE, echo=FALSE}


ggplot(data = zip) + geom_point(aes(x=prop_white, y=arrest_rate, color = population_density)) +theme_linedraw()+ ggtitle("Proportion of Residents Who are White vs. Normalized Arrest Rate")
ggplot(data=zip) + geom_point(aes(x=prop_white, y=median_home_value))+theme_linedraw()+ ggtitle("Proportion of Residents Who are White vs. Median Home Value")
ggplot(data=zip) + geom_point(aes(x=population_density, y=arrest_rate))+theme_linedraw()+ ggtitle("Normalized Arrest Rate vs ZipCode Population Density(People/Sq Mile)")


```

```{r data_description, message=FALSE, warning=FALSE, echo=FALSE}
table <- merge(obs, zip, by = "zipcode") %>% drop_na()

Variable <- c("clearance_status", "zipcode", "population_density", "median_income", "median_home_value", "prop_white", "arrest_rate")

Description <- c("whether or not crime is cleared by arrest", " postal zipcode in Austin, TX", "people per square mile", "median income of postal zipcode", "median home value of postal zipcode","proportion of postal zipcode that is white","proportion of crimes cleared by arrest relative to total crimes")

Type <- c("numeric" , "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")

vars_of_interest <- data.frame(Variable, Description, Type)

kable(vars_of_interest, caption = "Data Dictionary")

```


# Models
## First Model: Logistic Regression

We started modeling by recoding dependent variable `clearance_status` to take on the unit value if crime is cleared by arrest and zero otherwise. Also, we dropped all nulls before creating a train/test split with 80 percent of the data going to the training set, while the remaining 20 percent ending up in the testing set data. In our analysis, we chose to include population density, median income, median home price, white population share, and arrest rate as independent variables. The resulting model is 
\
&nbsp;
  $$
  P(clearance_status = 1 \mid x_{i,t}) = \beta_0 + \beta_1 population_density_{i,t} + \beta_2 median_income_{i,t} + \beta_3 median_home_value_{i,t} + \beta_3 prop_white_{i,t} + \beta_4 arrest_rate _{i,t}
  $$
\
&nbsp;
The results reveal that `arrest rate`, `median home price`, and `white population share` are highly significant in predicting `clearance_status`, so they should be included in the model. Then, out of sample root mean square error (RMSE) is calculated as a measure of the modelâ€™s out of sample performance. RMSE will be used to compare across all models, and the lower, the better.

```{r Logistic, message=FALSE, warning=FALSE, echo=FALSE}
<<<<<<< HEAD
=======
set.seed(1)
>>>>>>> b89a03112af8b02006870598a7e4b90adca6ad06

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)

crime_logit <- glm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate,
                   data = crime_train, family = binomial)



rmse_frame_logit=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)


modelr::rmse(crime_logit,crime_test)
} %>% as.data.frame
# validate_RMSE_logit <- mean(rmse_frame_logit$V1)
## Validated RMSEout of 2.03

validate_RMSE_logit <- data.frame(mean(rmse_frame_logit$V1))
colnames(validate_RMSE_logit) <- "RMSE"
rownames(validate_RMSE_logit) <- "Logit" 
kable(validate_RMSE_logit)
```




## Second Model: Stepwise Selection
```{r Stepwise, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(2)
#crime_step <- step(crime_logit, scope=~(.)^2)
# stepwise function chose the following model
crime_step <- glm(clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + zipcode + population_density:median_income + 
    median_home_value:arrest_rate + median_income:median_home_value + 
    median_income:prop_white, data = crime_train, family = binomial)

rmse_frame_step=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)


modelr::rmse(crime_step,crime_test)
} %>% as.data.frame
# validate_RMSE_step = mean(rmse_frame_step$V1)
## Validated RMSEout of 2.26

validate_RMSE_step <- data.frame(mean(rmse_frame_step$V1))
colnames(validate_RMSE_step) <- "RMSE"
rownames(validate_RMSE_step) <- "Stepwise Selection" 
kable(validate_RMSE_step)
```

In terms of the types of models, we started with a baseline logistic regression model, with the specification of clearance_status on everything else. After that, using the stepwise variable selection function, we computed the best set of variables and the interaction between them which performed the best. The logistic model chose by the stepwise function is 

`clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + zipcode + median_home_value:arrest_rate + 
    median_income:arrest_rate + median_home_value:zipcode + median_income:prop_white + 
    prop_white:arrest_rate + arrest_rate:zipcode + population_density:prop_white + 
    population_density:median_home_value + population_density:arrest_rate`
    
## Third Model: Random Forest 
```{r Random Forest, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(3)
rmse_frame_forest=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)

crime_forest <- randomForest(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    data = omit_train,
                    importance = TRUE, na.action = na.omit)

modelr::rmse(crime_forest,omit_test)
} %>% as.data.frame
# validate_RMSE_forest = mean(rmse_frame_forest$V1) 
## Validated RMSEout of .353

validate_RMSE_forest <- data.frame(mean(rmse_frame_forest$V1))
colnames(validate_RMSE_forest) <- "RMSE"
rownames(validate_RMSE_forest) <- "Random Forest" 
kable(validate_RMSE_forest)
```

We repeated the process for gradient boosted models. We used Gradient Boosting models with distribution as "gaussian", the number of trees 
as 10000, shrinkage as 0.01,and with a interaction depth of 4.

## Fourth Model: Gradient Boosting
```{r Gradient Boosting, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(4)
rmse_frame_gbm=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)


crime_gbm <- gbm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                 data = crime_train,
                 distribution = "gaussian",
                 n.trees = 500,
                 shrinkage = 0.01, interaction.depth = 4, cv.folds = 2)

modelr::rmse(crime_gbm,omit_test)
} %>% as.data.frame
# validate_RMSE_gbm = mean(rmse_frame_gbm$V1) 
## RMSEout of .351

validate_RMSE_gbm <- data.frame(mean(rmse_frame_gbm$V1))
colnames(validate_RMSE_gbm) <- "RMSE"
rownames(validate_RMSE_gbm) <- "Gradient Boosting" 
kable(validate_RMSE_gbm)
```

## Fifth Model: Lasso Model
```{r Lasso, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(5)
x <- model.matrix(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + as.factor(zipcode),
                  data = table)[,-1] 
#[, -1] excludes first col (intercept)

x <- scale(x, center = TRUE, scale = TRUE) 
y <- table$clearance_status %>% as.factor()
grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x, y, alpha = 1, lambda = grid, family = "binomial")
cv.out <- cv.glmnet(x, y, alpha = 1, family = "binomial", folds=20)
bestlam <- cv.out$lambda.min

plot(lasso.mod)
title("Figure 1: Lasso Coefficients as a Function of L1 Norm", line = 3)

```

```{r Lasso2, warning=FALSE, echo=FALSE}
plot(cv.out)
title("Figure 2: Mean-Squared Error as a Function of log Lambda", line = 3)
```

```{r Lasso3, warning=FALSE, echo=FALSE}
table <- merge(obs, zip, by = "zipcode") %>% drop_na()
table$zipcode = as.factor(table$zipcode)

lasso.coef <- predict(lasso.mod,
                      type = "coefficients",
                      s = bestlam)

LassoCoef <- as.data.table(as.matrix(lasso.coef), keep.rownames = TRUE)
kable(LassoCoef, col.names = c("Predictor", "Estimate"), caption = "**Table 1 Lasso Model Predictor Estimates**", format_caption = c("italic", "underline")) %>%
    kable_styling(bootstrap_options = "striped", full_width = F)


mse = min(cv.out$cvm)
rmse = sqrt(mse)
# .9062
validate_RMSE_lasso <- data.frame(sqrt(mse))
colnames(validate_RMSE_lasso) <- "RMSE"
rownames(validate_RMSE_lasso) <- "Lasso" 
kable(validate_RMSE_lasso)

```


## Confusion Matrix for the best model...
```{r Validation_GBM, message=FALSE, warning=FALSE, echo=FALSE}

pred =predict(crime_gbm,newdata=crime_test)
confusion_table = data.frame(fold_id=integer(),TPR=integer(),FPR=integer())

level = seq(.05,.5,by=.05)

confusion_level=foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}

gbm_accuracy = (6014+51)/(6014+1023+32+51) # 85.2% accuracy

confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for GBM Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)
accurac7120
gbm_auc = auc(crime_test$clearance_status,pred)
## .669
```
## Confusion Matrix for the second best model...
```{r Validation_RF, message=FALSE, warning=FALSE, echo=FALSE}

pred =predict(crime_forest,newdata=crime_test)
confusion_table = data.frame(fold_id=integer(),TPR=integer(),FPR=integer())

level = seq(.05,.5,by=.05)

confusion_level=foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}


confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for Random Forest Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)


forest_auc = auc(crime_test$clearance_status,pred)
## .667

```

## Sanity-Check: Confusion Matrix for the logit model...
```{r Sanity-Check - Logit Performance, message=FALSE, warning=FALSE, echo=FALSE}

pred = predict(crime_logit, crime_test, type='response')
confusion_table = data.frame(fold_id=integer(),TPR=integer(),FPR=integer())

level = seq(.1,.5,by=.05)

confusion_level=foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}


confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for Random Forest Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)


logit_auc = auc(crime_test$clearance_status,pred)
## .661

```



```{r Variable Importance, message=FALSE, warning=FALSE, echo=FALSE}
## Variable Importance Plots

vi = varImpPlot(crime_forest, type=1)

omit_test = as.data.frame(table)
partialPlot(crime_forest, table, 'prop_white')
partialPlot(crime_forest, table, 'median_home_value')
partialPlot(crime_forest, table, 'median_income')
partialPlot(crime_forest, table, 'population_density')

```