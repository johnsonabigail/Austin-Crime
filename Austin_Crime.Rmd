---
title: "Austin_Crime"
author: "Kevin, Elle, Abigail"
date: "5/4/2022"
output: md_document
---

```{r Loading Libraries, echo=TRUE, message=FALSE, warning=FALSE, show=FALSE}
library(tidyverse)
library(mosaic)
library(ggplot2)
library(dplyr)
library(stringr)
library(tidyr)
library(ggmap)
library(geojsonio)
library(broom)
library(data.table)
library(rsample)
library(caret)
library(modelr)
library(knitr)
library(parallel)
library(foreach)
library(pdp)
library(rpart)
library(rpart.plot)
library(gbm)
library(randomForest)
```

# Data Visualization
## Feature Engineering and Data Loading
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
obs <- read_csv("austin_crime.csv")

# Encode the crime target variable of interest
# 1 if "Cleared by Arrest", 0 otherwise
obs$clearance_status <- ifelse(obs$clearance_status == "Cleared by Arrest", 1, 0)

# Omit any missing rows for clearance status
obs <- filter(obs, clearance_status != "NA")
# This result in ~40k observations being dropped

# We determine the arrest rate, and append it to our zip-code level data
t1 <- obs %>% mutate(number_crimes = n_distinct(unique_key)) %>%
    group_by(zipcode) %>% 
    summarise(arrest_rate =(sum(clearance_status))/sum(number_crimes))

zip_list <- as.data.frame(t1$zipcode)
zip_list <- as.character(zip_list$`t1$zipcode`)

zip <- read_csv("austin_crime_zips.csv")
zip <- select(zip, 
              c(zipcode, population_density, median_income, median_home_value,
                prop_white,arrest_rate))
zip$arrest_rate <- scale(zip$arrest_rate)
zip$zipcode <- as.character(zip$zipcode)


tx <- geojson_read("tx_zip_geo.json", what = "sp")


## Final cleaning steps: Encoding zip as a factor with 45 levels, and dropping NA values
## Resulting in 27459 observations remaining
table <- merge(obs, zip, by = "zipcode") %>% drop_na()
table$zipcode = as.factor(table$zipcode)


```

# Data Visualization
## Subsetting geojson
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
# Subsetting our geojson such that only the zipcodes of interest are included...

# Transforming to a frame for ggplot...
tx_fortified <- tidy(tx, region = "ZCTA5CE10")
tx_sub <- setDT(tx_fortified)[id %chin% zip_list]

tx_sub <- tx_sub %>% left_join(.,zip, by= c("id"="zipcode"))
tx_sub <- na.omit(tx_sub)

```

# Data Visualization
## Visualizing
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
options(scipen = 10000)

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_income, x = long, y = lat, group = group,), color = 'black') + ggtitle("Median Income in Austin Area Zipcodes (USD)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_home_value, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Median Home Value in Austin Area Zipcodes (USD)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = prop_white, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Proportion of Population that is White in Austin Zipcodes")

ggplot() + geom_polygon(data = tx_sub, aes(fill = arrest_rate, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Normalized Proportion of Police Reports Leading to Arrest in Austin Zipcodes")
```

# Models
## First Model: Logistic Regression
```{r Logistic, message=FALSE, warning=FALSE, echo=FALSE}


rmse_frame_logit=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)

crime_logit <- glm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                   data = crime_train, family = binomial)

modelr::rmse(crime_logit,crime_test)
} %>% as.data.frame
validate_RMSE_logit = mean(rmse_frame_logit$V1)
## Validated RMSEout of 2.033


phat_test_crime <- predict(crime_logit, crime_test, type='response')
yhat_test_crime <- ifelse(phat_test_crime > 0.5, 1, 0)
confusion_out_logit <- table(y = crime_test$clearance_status, 
                             yhat = yhat_test_crime)
accuracy <- (confusion_out_logit[1,1] + confusion_out_logit[2,2])/sum(confusion_out_logit)



kable(table %>% group_by(zipcode) %>% summarize(count = n()) %>% rbind(data.frame(zipcode = "total", count = 17502)))
```




## Second Model: Stepwise Selection
```{r Stepwise, message=FALSE, warning=FALSE, echo=FALSE}
#crime_step <- step(crime_logit, scope=~(.)^2)

rmse_frame_step=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)


# stepwise function chose the following model
crime_step <- glm(clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + zipcode + population_density:median_income + 
    median_home_value:arrest_rate + median_income:median_home_value + 
    median_income:prop_white, data = crime_train, family = binomial)

modelr::rmse(crime_step,crime_test)
} %>% as.data.frame
validate_RMSE_step = mean(rmse_frame_step$V1)
## Validated RMSEout of 2.2

```

In terms of the types of models, we started with a baseline logistic regression model, with the specification of clearance_status on everything else. After that, using the stepwise variable selection function, we computed the best set of variables and the interaction between them which performed the best. The logistic model chose by the stepwise function is 

`clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + zipcode + median_home_value:arrest_rate + 
    median_income:arrest_rate + median_home_value:zipcode + median_income:prop_white + 
    prop_white:arrest_rate + arrest_rate:zipcode + population_density:prop_white + 
    population_density:median_home_value + population_density:arrest_rate`
    
## Third Model: Random Forest 
```{r Random Forest, message=FALSE, warning=FALSE, echo=FALSE}

rmse_frame_forest=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)

crime_forest <- randomForest(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    data = omit_train,
                    importance = TRUE, na.action = na.omit)

modelr::rmse(crime_forest,omit_test)
} %>% as.data.frame
validate_RMSE_forest = mean(rmse_frame_forest$V1) 
## Validated RMSEout of .352!!
```

We repeated the process for gradient boosted models. We used Gradient Boosting models with distribution as "gaussian", the number of trees 
as 10000, shrinkage as 0.01,and with a interaction depth of 4.

## Fourth Model: Gradient Boosting
```{r Gradient Boosting, message=FALSE, warning=FALSE, echo=FALSE}

rmse_frame_gbm=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)


crime_gbm <- gbm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                 data = crime_train,
                 distribution = "gaussian",
                 n.trees = 500,
                 shrinkage = 0.01, interaction.depth = 4, cv.folds = 2)

modelr::rmse(crime_gbm,omit_test)
} %>% as.data.frame
validate_RMSE_gbm = mean(rmse_frame_gbm$V1) 
## RMSEout of .3495

```

## Sixth Model: KNN Model (error out)
```{r KNN, message=FALSE, warning=FALSE, echo=FALSE}
trctrl <- trainControl(method = "cv",
                       number = 5,
                       savePredictions=TRUE,
                       allowParallel = TRUE,
                       classProbs = TRUE)
crime_knn1 <- train(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    data = crime_train,
                    method = "knn", 
                    trControl = trctrl,
                    family = "binomial",
                    tuneLength=20)

crime_knn_rmse <- data.frame(matrix(c(
crime_knn1$results[crime_knn1$results$RMSE == crime_knn1$results$RMSE %>% min, 1] %>% as.integer(), 
crime_knn1$results[crime_knn1$results$RMSE == crime_knn1$results$RMSE %>% min, 2]), nrow = 2)) 

colnames(crime_knn_rmse) = c("knn")
rownames(crime_knn_rmse) = c('k', "RMSE")
kable(crime_knn_rmse)

crime.knn <- knnreg(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    k = 5,
                    data = crime_train)

```

## Seventh Model: Lasso Model
```{r Lasso, message=FALSE, warning=FALSE, echo=FALSE}
x <- model.matrix(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                  data = table)[,-1] 
#[, -1] excludes first col (intercept)

x <- scale(x, center = TRUE, scale = TRUE) 
y <- table$clearance_status %>% as.factor()
grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x, y, alpha = 1, lambda = grid, family = "binomial")
cv.out <- cv.glmnet(x, y, alpha = 1, family = "binomial")
bestlam <- cv.out$lambda.min

plot(lasso.mod)
title("Figure 1: Lasso Coefficients as a Function of L1 Norm", line = 3)
```

```{r Lasso2, warning=FALSE, echo=FALSE}
plot(cv.out)
title("Figure 2: Mean-Squared Error as a Function of log Lambda", line = 3)
```

```{r Lasso3, warning=FALSE, echo=FALSE}
lasso.coef <- predict(lasso.mod,
                      type = "coefficients",
                      s = bestlam)

LassoCoef <- as.data.table(as.matrix(lasso.coef), keep.rownames = TRUE)
kable(LassoCoef, col.names = c("Predictor", "Estimate"), caption = "**Table 1 Lasso Model Predictor Estimates**", format_caption = c("italic", "underline")) %>%
    kable_styling(bootstrap_options = "striped", full_width = F)
```


## RMSE not done yet
```{r rmse, message=FALSE, warning=FALSE, echo=FALSE}
crime_rmse <- data.frame(
modelr::rmse(crime_logit, crime_test),
modelr::rmse(crime_step, crime_test),
modelr::rmse(crime_tree1, crime_test),
modelr::rmse(crime.prune, crime_test),
modelr::rmse(crime_forest1, crime_test),
modelr::rmse(crime.gbs, crime_test),
modelr::rmse(crime.knn, crime_test),
modelr::rmse(lasso.mod, crime_test))
colnames(crime_rmse) = c("Logit", "Stepwise", "Tree", "Pruned Tree", "Forest", "GBM", "knn", "Lasso")
rownames(crime_rmse) = "RMSE"
kable(crime_rmse)
```
