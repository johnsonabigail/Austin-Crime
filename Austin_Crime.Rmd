---
title: "Austin_Crime"
author: "Kevin, Elle, Abigail"
date: "5/4/2022"
output: md_document
---

```{r Loading Libraries, echo=TRUE, message=FALSE, warning=FALSE, show=FALSE}
library(tidyverse)
library(mosaic)
library(ggplot2)
library(dplyr)
library(stringr)
library(tidyr)
library(ggmap)
library(geojsonio)
library(broom)
library(data.table)
library(rsample)
library(caret)
library(modelr)
library(knitr)
library(parallel)
library(foreach)
library(pdp)
library(rpart)
library(rpart.plot)
library(gbm)
library(randomForest)
```

# Data Visualization
## Feature Engineering and Data Loading
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
obs <- read_csv("austin_crime.csv")

# Encode the crime target variable of interest
# 1 if "Cleared by Arrest", 0 otherwise
obs$clearance_status <- ifelse(obs$clearance_status == "Cleared by Arrest", 1, 0)

# Omit any missing rows for clearance status
obs <- filter(obs, clearance_status != "NA")
# This result in ~40k observations being dropped

# We determine the arrest rate, and append it to our zip-code level data
t1 <- obs %>% mutate(number_crimes = n_distinct(unique_key)) %>%
    group_by(zipcode) %>% 
    summarise(arrest_rate =(sum(clearance_status))/sum(number_crimes))

zip_list <- as.data.frame(t1$zipcode)
zip_list <- as.character(zip_list$`t1$zipcode`)

zip <- read_csv("austin_crime_zips.csv")
zip <- select(zip, 
              c(zipcode, population_density, median_income, median_home_value,
                prop_white,arrest_rate))
zip$arrest_rate <- scale(zip$arrest_rate)
zip$zipcode <- as.character(zip$zipcode)


tx <- geojson_read("tx_zip_geo.json", what = "sp")

```

# Data Visualization
## Subsetting geojson
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
# Subsetting our geojson such that only the zipcodes of interest are included...

# Transforming to a frame for ggplot...
tx_fortified <- tidy(tx, region = "ZCTA5CE10")
tx_sub <- setDT(tx_fortified)[id %chin% zip_list]

tx_sub <- tx_sub %>% left_join(.,zip, by= c("id"="zipcode"))
tx_sub <- na.omit(tx_sub)

```

# Data Visualization
## Visualizing
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
options(scipen = 10000)

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_income, x = long, y = lat, group = group,), color = 'black')

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_home_value, x = long, y = lat, group = group,), color = 'black')

ggplot() + geom_polygon(data = tx_sub, aes(fill = prop_white, x = long, y = lat, group = group,), color = 'black')

ggplot() + geom_polygon(data = tx_sub, aes(fill = arrest_rate, x = long, y = lat, group = group,), color = 'black')
```

# Models
## First Model: Logistic Regression
```{r Logistic, message=FALSE, warning=FALSE, echo=FALSE}
table <- merge(obs, zip, by = "zipcode") %>% drop_na()

crime <- initial_split(table, prob = 0.8)
crime_train <- training(crime)
crime_test <- testing(crime)

crime_logit <- glm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                   data = crime_train, family = binomial)

phat_test_crime <- predict(crime_logit, crime_test, type='response')
yhat_test_crime <- ifelse(phat_test_crime > 0.5, 1, 0)
confusion_out_logit <- table(y = crime_test$clearance_status, 
                             yhat = yhat_test_crime)
accuracy <- (confusion_out_logit[1,1] + confusion_out_logit[2,2])/sum(confusion_out_logit)

rmse(crime_logit, crime_test)

kable(table %>% group_by(zipcode) %>% summarize(count = n()) %>% rbind(data.frame(zipcode = "total", count = 17502)))
```

## Second Model: Stepwise Selection
```{r Stepwise, message=FALSE, warning=FALSE, echo=FALSE}
crime_step <- step(crime_logit, scope=~(.)^2)

# stepwise function chose the following model
crime_step <- glm(clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + zipcode + population_density:median_income + 
    median_home_value:arrest_rate + median_income:median_home_value + 
    median_income:prop_white, data = crime_train, family = binomial)

```

In terms of the types of models, we started with a baseline logistic regression model, with the specification of clearance_status on everything else. After that, using the stepwise variable selection function, we computed the best set of variables and the interaction between them which performed the best. The logistic model chose by the stepwise function is 

`clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + zipcode + median_home_value:arrest_rate + 
    median_income:arrest_rate + median_home_value:zipcode + median_income:prop_white + 
    prop_white:arrest_rate + arrest_rate:zipcode + population_density:prop_white + 
    population_density:median_home_value + population_density:arrest_rate`
    
## Third Model: Tree
```{r Tree, message=FALSE, warning=FALSE, echo=FALSE}
trctrl <- trainControl(method = "cv", number = 5, savePredictions=TRUE)

crime_tree1 <- train(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                     data = crime_train,
                     method = "rpart",
                     trControl = trctrl,
                     tuneLength = 0)

crime_tree1$results$RMSE

crime.tree <- rpart(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode, 
                    data = crime_train,
                    control = rpart.control(cp = 0.002, minsplit=30))

prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)
}

crime.prune <- prune_1se(crime.tree)
```

## Fourth Model: Random Forest 
```{r Random Forest, message=FALSE, warning=FALSE, echo=FALSE}
trctrl <- trainControl(method = "cv", number = 5, savePredictions=TRUE, allowParallel = TRUE, classProbs = TRUE)

crime_forest1 <- train(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                       data = crime_train,
                       method = "rf",
                       family = "binomial",
                       trControl=trctrl,
                       prox=TRUE, tuneLength=1)

crime_forest_rmse <- data.frame(
crime_forest1$results$RMSE
)

colnames(crime_forest_rmse) = c("Random Forest")
rownames(crime_forest_rmse) = "RMSE"
kable(crime_forest_rmse)

crime.forest <- randomForest(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    data = crime_train,
                    importance = TRUE, na.action = na.omit)
```

We repeated the process for gradient boosted models. We used Gradient Boosting models with distribution as "gaussian", the number of trees 
as 10000, shrinkage as 0.01,and with a interaction depth of 4.

## Fifth Model: Gradient Boosting
```{r Gradient Boosting, message=FALSE, warning=FALSE, echo=FALSE}
crime_gbm1 <- gbm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                  data = crime_train,
                  distribution = "gaussian",
                  n.trees = 10000,
                  shrinkage = 0.01, interaction.depth = 4, cv.folds = 5)

crime_gbm1$cv.error %>% mean %>% sqrt

crime.gbs <- gbm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                 data = crime_train,
                 distribution = "gaussian",
                 n.trees = 10000,
                 shrinkage = 0.01, interaction.depth = 4, cv.folds = 5)
```

## Sixth Model: KNN Model (error out)
```{r KNN, message=FALSE, warning=FALSE, echo=FALSE}
trctrl <- trainControl(method = "cv",
                       number = 5,
                       savePredictions=TRUE,
                       allowParallel = TRUE,
                       classProbs = TRUE)
crime_knn1 <- train(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    data = crime_train,
                    method = "knn", 
                    trControl = trctrl,
                    family = "binomial",
                    tuneLength=20)

crime_knn_rmse <- data.frame(matrix(c(
crime_knn1$results[crime_knn1$results$RMSE == crime_knn1$results$RMSE %>% min, 1] %>% as.integer(), 
crime_knn1$results[crime_knn1$results$RMSE == crime_knn1$results$RMSE %>% min, 2]), nrow = 2)) 

colnames(crime_knn_rmse) = c("knn")
rownames(crime_knn_rmse) = c('k', "RMSE")
kable(crime_knn_rmse)

crime.knn <- knnreg(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    k = 5,
                    data = crime_train)

```

## Seventh Model: Lasso Model
```{r Lasso, message=FALSE, warning=FALSE, echo=FALSE}
x <- model.matrix(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                  data = table)[,-1] 
#[, -1] excludes first col (intercept)

x <- scale(x, center = TRUE, scale = TRUE) 
y <- table$clearance_status %>% as.factor()
grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x, y, alpha = 1, lambda = grid, family = "binomial")
cv.out <- cv.glmnet(x, y, alpha = 1, family = "binomial")
bestlam <- cv.out$lambda.min

plot(lasso.mod)
title("Figure 1: Lasso Coefficients as a Function of L1 Norm", line = 3)
```

```{r Lasso2, warning=FALSE, echo=FALSE}
plot(cv.out)
title("Figure 2: Mean-Squared Error as a Function of log Lambda", line = 3)
```

```{r Lasso3, warning=FALSE, echo=FALSE}
lasso.coef <- predict(lasso.mod,
                      type = "coefficients",
                      s = bestlam)

LassoCoef <- as.data.table(as.matrix(lasso.coef), keep.rownames = TRUE)
kable(LassoCoef, col.names = c("Predictor", "Estimate"), caption = "**Table 1 Lasso Model Predictor Estimates**", format_caption = c("italic", "underline")) %>%
    kable_styling(bootstrap_options = "striped", full_width = F)
```


## RMSE not done yet
```{r rmse, message=FALSE, warning=FALSE, echo=FALSE}
crime_rmse <- data.frame(
modelr::rmse(crime_logit, crime_test),
modelr::rmse(crime_step, crime_test),
modelr::rmse(crime_tree1, crime_test),
modelr::rmse(crime.prune, crime_test),
modelr::rmse(crime_forest1, crime_test),
modelr::rmse(crime.gbs, crime_test),
modelr::rmse(crime.knn, crime_test),
modelr::rmse(lasso.mod, crime_test))
colnames(crime_rmse) = c("Logit", "Stepwise", "Tree", "Pruned Tree", "Forest", "GBM", "knn", "Lasso")
rownames(crime_rmse) = "RMSE"
kable(crime_rmse)
```
