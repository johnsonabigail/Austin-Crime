---
title: "Austin_Crime"
author: "Kevin, Elle, Abigail"
date: "5/9/2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
always_allow_html: yes
---

```{r Loading Libraries, echo=TRUE, message=FALSE, warning=FALSE, show=FALSE}
library(tidyverse)
library(mosaic)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggmap)
library(geojsonio)
library(broom)
library(data.table)
library(rsample)
library(caret)
library(modelr)
library(knitr)
library(parallel)
library(foreach)
library(pdp)
library(rpart)
library(rpart.plot)
library(gbm)
library(randomForest)
library(glmnet)
library(kableExtra)
library(pROC)
```

# Abstract
The purpose of this report is to predict whether or not a crime is cleared by arrest, based on various demographic factors across Austin, TX. To build our analysis, we utilize data from the Austin Police Department and the U.S. Census Bureau, which includes information on reported crimes and demographics by zip code. We employ logistic regression, stepwise regression, random forest, gradient-boosted tree models, and lasso to predict crime clearance status. From these models, we select the random forest model as our best model with an AUC of 0.672 when validated against testing data. 


# Introduction
Whether in a large city or a small town, crime is an unforunate, yet ever-present, fact of society. While crime may be a constant reality, unique social and demographic factors create asymmetry in the way crime is both committed and penalized in a given city. Such is the case for Austin, TX. As a large metropolitan area covering several zip codes, each area of Austin has a unique composition of various social and demographic factors, which ultimately influence the way crime is penalized across Austin. While the type of crime committed has a clear impact on the resulting repercussions, the location in which crime is committed also seems to influence criminal consequences.  It begs the question of how much our social environment may skew legal decisions that should, ideally, be objective and just.

The motivation of this study is to build a model that accurately predicts the outcome of a criminal offense, based on the demographic factors of a crime's location.  This type of predictive analysis can be difficult, as no criminal offense is the same as another. Two crimes may both be classified as "theft", but one offense may have more clear evidence of the crime than the other. Therefore, the consequences may vary based on the specific details of each case. Some cases reside in a more "gray area" of what the just consequence should be. It is these cases that may be more susceptible to bias based on the demographics of their environment, such as income and race. Without the granular detail of each criminal offense, it can be hard to predict when these external factors truly have an effect. 

However, as more data regarding criminal action becomes publicly available, it is increasingly important that we build predictive models to understand the true magnitude of these external factors' influence on legal decisions. This paper is organized as follows. In Section 2, we describe the data used for our analysis and provide some initial visualizations. In Section 3, we present our statistical models, namely: Logistic, Stepwise Selection, Random Forest, Gradient Boosting, and Lasso. In Section 4 , we compare the performance of our models using confusion matrices and select the best performing model. Finally, we summarize our results and conclusions in Section 5.




# Data 
## Feature Engineering and Data Loading
```{r Data Cleaning, message=FALSE, warning=FALSE, echo=FALSE}
obs <- read_csv("austin_crime.csv")

# Encode the crime target variable of interest
# 1 if "Cleared by Arrest", 0 otherwise
obs$clearance_status <- ifelse(obs$clearance_status == "Cleared by Arrest", 1, 0)

# Omit any missing rows for clearance status
obs <- filter(obs, clearance_status != "NA")
# This result in ~40k observations being dropped

# We determine the arrest rate, and append it to our zip-code level data
t1 <- obs %>% mutate(number_crimes = n_distinct(unique_key)) %>%
    group_by(zipcode) %>% 
    summarise(arrest_rate =(sum(clearance_status))/sum(number_crimes))

zip_list <- as.data.frame(t1$zipcode)
zip_list <- as.character(zip_list$`t1$zipcode`)

zip <- read_csv("austin_crime_zips.csv")
zip <- select(zip, 
              c(zipcode, population_density, median_income, median_home_value,
                prop_white,arrest_rate))
zip$arrest_rate <- scale(zip$arrest_rate)
zip$zipcode <- as.character(zip$zipcode)


tx <- geojson_read("tx_zip_geo.json", what = "sp")


## Final cleaning steps: Encoding zip as a factor with 45 levels, and dropping NA values
## Resulting in 27459 observations remaining
table <- merge(obs, zip, by = "zipcode") %>% drop_na()
table$zipcode = as.factor(table$zipcode)
```

# Data
## Subsetting geojson
```{r Data Cleaning2, message=FALSE, warning=FALSE, echo=FALSE}
# Subsetting our geojson such that only the zipcodes of interest are included...

# Transforming to a frame for ggplot...
tx_fortified <- tidy(tx, region = "ZCTA5CE10")
tx_sub <- setDT(tx_fortified)[id %chin% zip_list]

tx_sub <- tx_sub %>% left_join(.,zip, by= c("id"="zipcode"))
tx_sub <- na.omit(tx_sub)

```

The GeoJSON we found has the boundaries of every zipcode in Texas. We subset this JSON based on the zipcodes included in our dataset.

# Data
## Summary and Description
```{r data_description, message=FALSE, warning=FALSE, echo=FALSE}
table <- merge(obs, zip, by = "zipcode") %>% drop_na()

Variable <- c("clearance_status", "zipcode", "population_density", "median_income", "median_home_value", "prop_white", "arrest_rate")

Description <- c("whether or not crime is cleared by arrest", " postal zipcode in Austin, TX", "people per square mile", "median income of postal zipcode", "median home value of postal zipcode","proportion of postal zipcode that is white","proportion of crimes cleared by arrest relative to total crimes")

Type <- c("numeric" , "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")

vars_of_interest <- data.frame(Variable, Description, Type)

kable(vars_of_interest, caption = "Table (1) Data Dictionary")

```

The data used in this analysis is from the Austin Police Department Crime Reports Data. This dataset only includes incidents during 2014-2015 that the Austin Police Department responded to and wrote a report. One incident could have several offenses associated with it, however, only the highest offense is recorded in the dataset. The dataset includes information about the exact location, zipcode, time, and particular offense for each incident. Additionally, this dataset includes information about the clearance status for each recorded offense. The clearance status defines how or whether a crime was solved using three categories: Not cleared, Cleared by Exception, and Cleared by Arrest. For our study, the 'Cleared by Arrest' category is our chosen clearance status of interest. Therefore, we re-coded clearance status as a binary indicator, where Cleared by Arrest is equal to one, and zero otherwise. Additionally, we re-coded zipcode as a factor in order to include each zipcode in our models while also maintaining interpretability. 

In addition to the Austin Police Department data, we used U.S. Census Bureau data to collect demographic information for each zipcode in the crime report dataset. Specifically, we gathered information about the population density, median income, median home value, arrest rate, and racial composition for each zipcode. 

As an additional feature of interest, we create "arrest rate" as a new feature in the dataset. Arrest rate is the proportion of crimes cleared by arrest relative to the total number of crimes in each zip code.  This helps us understand which areas in Austin tend to be high arrest areas, therefore adding predictive power to the likelihood a crime is cleared by arrest based on its zip code. Also, as this feature is relatively flat, we decided to z-score the arrest rate, so we can more easily understand relative differences between different areas.

As a final step to create a data set for modeling,  we include latitude and longitude boundaries for each zip code of interest. This allows us to visualize group trends in Austin by each zip code, and understand the asymmetry of demographic factors in the Austin metropolitan. Figure 2 and Figure 3 show median income by zip code and median home value by zip code, respectively. We can clearly see a correlation between income and home value, with most high income and high valued homes on the west side of Austin. 



# Data
## Visualizing Zipcodes
```{r Data Cleaning3, message=FALSE, warning=FALSE, echo=FALSE}
options(scipen = 10000)

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_income, x = long, y = lat, group = group,), color = 'black') + ggtitle("Median Income in Austin Area Zipcodes (USD)") + labs(caption = "Figure (2)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = median_home_value, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Median Home Value in Austin Area Zipcodes (USD)") + labs(caption = "Figure (3)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = prop_white, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Proportion of Population that is White in Austin Zipcodes") + labs(caption = "Figure (4)")

ggplot() + geom_polygon(data = tx_sub, aes(fill = arrest_rate, x = long, y = lat, group = group,), color = 'black')+ ggtitle("Normalized Proportion of Police Reports Leading to Arrest in Austin Zipcodes") + labs(caption = "Figure (5)")

```

Figure 4 shows the proportion of the population that is white by zip code. This plot shows a clear trend of a more white population on the west side of Austin, and a more minority population on the east side. When comparing this to Figure 2 and Figure 3, we can see that the west side of Austin is wealthier and more white, while the east side is less wealthy and less white. Do these trends correlate with arrest rates? 

Figure 5 shows the average arrest rate by zip code. There does not appear to be a clear trend of certain areas with high or low arrest rates. However, one northwest zip code experiences a notably high arrest rate. This particular area of Austin is relatively more white, but of lower income status. However, this area has an extremely low population density, and only a few observations of crimes, so we have to understand that lower density areas with fewer observations may skew results in our analysis. When ignoring outliers, it would appear that median income may be one of the more important factors in determining the arrest rate. One might conclude that community law enforcement budgets are shaped by the prevailing wealth and taxes collected in those areas. 




# Question: Does Race play a part in the prevailing arrest rate?
## A visualization
```{r Ethnicity Effects, message=FALSE, warning=FALSE, echo=FALSE}

ggplot(data = zip) + geom_point(aes(x=prop_white, y=arrest_rate, color = population_density)) +theme_linedraw()+ ggtitle("Proportion of Residents Who are White vs. Normalized Arrest Rate")+ labs(caption = "Figure (6)")

```

Of high interest in today's political landscape is the implications of ethnicity in justice outcomes. What relationships does ethnicity have in the prevailing arrest rate in a community? If you are white, is your police report more likely to lead to an arrest? Figure 6, shows that, at least in Austin, there does not appear to be a clear trend. To understand whether or not there are outliers skewing results, the figure also accounts for population density, measured in people per square mile. We notice that there are several outliers in low density areas. There appears to be no readily obvious trend.However, we will run some models to see if such an assumption can be justified statistically.



# Methods
## Summary
To attempt to predict the outcome of 'clearance_status', we will run a model horse race, and select the model that returns the lowest validated RMSEout. To validate each model, we will calculate the RMSEout for a train/test split 10 times, and take the average from the ten samples to provide a more robust estimate for comparison. After we select the best model, we will generate ROC curves, and calculate AUC.

## First Model: Logistic Regression
We started modeling by recoding dependent variable `clearance_status` to take on the unit value if crime is cleared by arrest and zero otherwise. Also, we dropped all nulls before creating a train/test split with 80 percent of the data going to the training set, while the remaining 20 percent ending up in the testing set data. In our analysis, we chose to include population density, median income, median home price, white population share, and arrest rate as independent variables. The resulting model is 
\
&nbsp;
  $$
  P(clearance \: status = 1 \mid x_{i,t}) = \beta_0 + \beta_1 population \: density_{i,t} + \beta_2 median \: income_{i,t} + \beta_3 median \: home \: value_{i,t} + \beta_3 prop \: white_{i,t} + \beta_4 arrest \: rate _{i,t}
  $$
\
&nbsp;
The results reveal that `arrest rate`, `median home price`, and `white population share` are highly significant in predicting `clearance_status`, so they should be included in the model. Then, out of sample root mean square error (RMSE) is calculated as a measure of the model’s out of sample performance. RMSE will be used to compare across all models, and the lower, the better.

Each coefficient shows a ceteris paribus effect of every feature on clearance status. For instance, $\beta_{prop \: white}=-0.67 means that as the share of the white population increases by 1 percent, the probability of crime is cleared by arrest declines by 67 percentage points, holding all other features constant. 

```{r Logistic, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(1)

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)

crime_logit <- glm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate,
                   data = crime_train, family = binomial)



rmse_frame_logit=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)


modelr::rmse(crime_logit,crime_test)
} %>% as.data.frame
# validate_RMSE_logit <- mean(rmse_frame_logit$V1)
## Validated RMSEout of 2.0318

validate_RMSE_logit <- data.frame(mean(rmse_frame_logit$V1))
# 2.03
```

## Second Model: Stepwise Selection
Although the logistic model is simple, it fails to capture context-specific effects by ignoring interaction terms. Stepwise selection computes the best set of variables by including main effects, and pairwise interaction terms that result in the lowest RMSE. The resulting model chosen by stepwise selection is 
\
&nbsp;
    $$
  P(clearance \: status = 1 \mid x_{i,t}) = \beta_0 + \beta_1 population \: density_{i,t} + \beta_2 median \: income_{i,t} + \beta_3 median \: home \: value_{i,t} + \beta_3 prop \: white_{i,t} + \beta_4 arrest \: rate_{i,t} + \beta_5 median\:home\:value \times arrest\:rate
  $$
\
&nbsp;

We notice an interaction term in our model. This term allows the effect of a unit change in $median\:home\:value$ to depend on $arrest\:rate$. The coefficient of this interaction term measures the effect on clearance status of an additional dollar of median home value is greater, by the amount $\beta_5$, for each additional percentage point increase in arrest rate.

By including the interaction term, the model performance is enhanced. RMSE declined from 2.0318 to 2.0254. Other models will be considered in the following sections with the goal of reducing RMSE further.

```{r Stepwise, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(2)
crime_step <- step(crime_logit, scope=~(.)^2)
# stepwise function chose the following model
crime_step <- glm(clearance_status ~ population_density + median_income + median_home_value + 
    prop_white + arrest_rate + median_home_value:arrest_rate, data = crime_train, family = binomial)

rmse_frame_step=foreach(x=1:10, .combine='rbind')%do%{

x <- initial_split(table, prob = 0.8)
crime_train <- training(x)
crime_test <- testing(x)


modelr::rmse(crime_step,crime_test)
} %>% as.data.frame
# validate_RMSE_step = mean(rmse_frame_step$V1)
## Validated RMSEout of 2.0254

validate_RMSE_step <- data.frame(mean(rmse_frame_step$V1))
## 2.04
```
    
## Third Model: Random Forest 
The next model performed is random forest. The highlight of tree is that it automatically detect nonlinearities and interactions. So there is no need to include interaction terms. The process involves resampling the data with replacement 500 times and fitting a tree to each one. Then, averaging the predictions of the 500 different trees. However, we can reduce covariance between each tree by using only a subset of the variables. Thus, the 500 trees are diversified and their predictions are less correlated. By introducing more randomness to the process, we can improve both accuracy and prevent over-fitting. The resulting RMSE is 0.3522 which is a significant improvement from the logistic model or stepwise selection.

Figure [figure number here] presents a variable importance plot. It shows that excluding zip code would increase mean square error (MSE) by 26 percent, suggesting that zip code should be included in the model. The process of the calculation involves comparing out-of-bag performance of the model when using the correct zip code versus permuting the zip code for all observations.

```{r Random Forest, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(3)
rmse_frame_forest=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)

crime_forest <- randomForest(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                    data = omit_train,
                    importance = TRUE, na.action = na.omit)

modelr::rmse(crime_forest,omit_test)
} %>% as.data.frame
validate_RMSE_forest = mean(rmse_frame_forest$V1)
## Validated RMSEout of .3522
```


## Fourth Model: Gradient Boosting
Similarly to the random forest model in the previous section, boosting combines many decision trees where each tree is fitted to the residual of the previous tree. However, the fit in each round will be scaled down to constrain it from explaining the full variation in the data. The resulting estimate is the sum of all crushed trees in each round. The highlight of the gradient boosting technique is that it keeps each tree in the ensemble from overfitting just like when random forest restricts the number of features to prevent overfitting.

Boosting requires choosing three main hyper parameters: (1) Number of trees: 500, (2) Shrinkage Parameter: 0.01, and (3) Interaction Depth: 4

```{r Gradient Boosting, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(4)
rmse_frame_gbm=foreach(x=1:10, .combine='rbind')%do%{
x = initial_split(table, prop = 0.8)
omit_train = training(x)
omit_test = testing(x)


crime_gbm <- gbm(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + zipcode,
                 data = crime_train,
                 distribution = "bernoulli",
                 n.trees = 500,
                 shrinkage = 0.01, interaction.depth = 4, cv.folds = 2)

modelr::rmse(crime_gbm,omit_test)
} %>% as.data.frame
validate_RMSE_gbm = mean(rmse_frame_gbm$V1) 
## RMSEout of 1.984

```

## Fifth Model: Lasso Model
```{r Lasso, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(5)
x <- model.matrix(clearance_status ~ population_density + median_income + median_home_value + prop_white + arrest_rate + as.factor(zipcode),
                  data = table)[,-1] 
#[, -1] excludes first col (intercept)

x <- scale(x, center = TRUE, scale = TRUE) 
y <- table$clearance_status %>% as.factor()
grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x, y, alpha = 1, lambda = grid, family = "binomial")
cv.out <- cv.glmnet(x, y, alpha = 1, family = "binomial", folds=20)
bestlam <- cv.out$lambda.min

mse = min(cv.out$cvm)
rmse = sqrt(mse)
# .9062
```

# Results
## Model Performance Summary
```{r Result Summary, warning=FALSE, echo=FALSE}

# Results
Model <- c("Logit", "Stepwise Selection", "Random Forest", "Gradient Boosting", "Lasso")

RMSEout <- c("2.03" , "2.04", ".352", "1.984", ".9062")

vars_of_interest <- data.frame(Model, RMSEout)

kable(vars_of_interest, caption = "Table (2) Modeling Results")
```

Of the five models we tried to run, the random forest model outperformed all others, with a validated RMSEout of .352. From here, we will make predictions against the testing dataset, generate a ROC curve, and calculate AUC.


## ROC Curve for best model by RMSEout
```{r Validation_RF, message=FALSE, warning=FALSE, echo=FALSE}

pred =predict(crime_forest,newdata=crime_test)
confusion_table = data.frame(fold_id=integer(),TPR=integer(),FPR=integer())

level = seq(.05,.5,by=.05)

confusion_level=foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}


confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for Random Forest Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)+ labs(caption = "Figure (7)")


forest_auc = auc(crime_test$clearance_status,pred)
## .672

```

As we see in figure 7, the RF model outperforms a 50/50 guess. When calculating AUC, we return .672. To make a comparison, does Random Forest outperform a more general model? When comparing to the results of the more simple logit model, we see that the random forest has 2.5% more AUC. (See appendix), and hence, as more predictive power. When we graph variable importance, we observe that the prevailing arrest rate in each zipcode is most important in regards to percent increase in MSE if omitted, followed by population density, and median income. Clearly, jurisdictional effects are of the greatest predictive power. We do observe a small effect of ethnicity, which could potentially be explained by systemic biases, but the effect is marginal in comparison, and we cannot state such with any meaningful degree of confidence. Population density also plays a significant part. One might infer that in higher density areas, there is a greater police presence.

# Conclusion
After comparing five different methods, we select the best predictive model with an AUC measure of 0.672. This means our best model only correctly predicts about 67% of crime clearance statuses. While our rate of accurate prediction is better than a random guess, it still leaves a large margin for improvement. Our model uses demographic information at the aggregate level to predict crime clearance outcomes at the individual level. Therefore, our predictive power may be limited by our lack demographic information for each individual in the police report data set. Using data with both crime report and demographic information at the individual level, may improve the predictive performance of future studies. Moreover, future studies may want to include more features focused on income and economic factors, as these features seem to carry important predictive power for crime clearance status. With a more comprehensive data set and additional economic features, future studies likely will see improved model performance. 



# Appendix
## Sanity-Check: ROC Curve for the logit model
```{r Sanity-Check - Logit Performance, message=FALSE, warning=FALSE, echo=FALSE}

pred = predict(crime_logit, crime_test, type='response')
confusion_table = data.frame(fold_id=integer(),TPR=integer(),FPR=integer())

level = seq(.1,.6,by=.05)

confusion_level=foreach(x=level)%do%{
yhat_test = ifelse(pred > x,1,0)
confusion_out = table(y=crime_test$clearance_status, yhat = yhat_test)
TPR = (confusion_out[2,2]/(confusion_out[2,1]+confusion_out[2,2]))
FPR = (confusion_out[1,2]/(confusion_out[1,1]+confusion_out[1,2]))
confusion_table[nrow(confusion_table)+1,] = c(x,TPR,FPR)
}


confusion_table %>% ggplot(aes(FPR,TPR)) + geom_line(fill="steelblue") + labs(y= "True Positive Rate", x="False Positive Rate", title = "ROC Curve for Logit Model")+theme_linedraw() + geom_abline(slope=1,intercept = 0)+ labs(caption = "Figure (7)")



logit_auc = auc(crime_test$clearance_status,pred)
## .655

```
# Appendix
## Sanity-Check: Variable Importance Plot for RF model
```{r Variable Importance, message=FALSE, warning=FALSE, echo=FALSE}
## Variable Importance Plots

vi = varImpPlot(crime_forest, type=1)
```
